---
title: 图生图
toc: content
order: 4
group:
  title: 实战
---

# 图生图（二次元风格）简单案例文档
---

## 🎯 案例概述
本案例是一个**基于二次元模型的图生图工作流**，核心目标是：以一张动漫风格底图为基础，结合文本提示词优化画面细节，最终生成保留原图构图、同时满足“红色头发+绿色眼睛+森林背景”的高质量二次元图像。

工作流核心依赖：
- 主模型：`AnythingXL_v50-动漫.safetensors`（二次元专用生成模型）
- 优化 VAE：`ka-f8-anime2-vae-动漫优化.safetensors`（提升动漫图像细节与色彩）

---

![图片](/comfyui-doc/practical/img/img2img.png)
[下载示例文件(JSON)](/practical/json/img2img.json)

## 📋 前置准备
在搭建工作流前，请确保以下内容已完成：
1.  **模型存放**
    - 主模型（Checkpoint）：放入 `ComfyUI/models/checkpoints/` 目录
    - VAE 模型：放入 `ComfyUI/models/vae/` 目录
2.  **素材准备**
    - 准备一张二次元风格底图（本案例中为 `test.png`），用于图生图的初始图像输入

---

## 🛠️ 节点搭建与详解
以下按数据流顺序，逐个解析工作流中的节点配置与作用：

### 1. Checkpoint 加载器（简易）
- **作用**：加载核心生成模型（Checkpoint），提供生成图像的基础能力
- **参数设置**：选择 `AnythingXL_v50-动漫.safetensors`
- **输出连线**：
  - `模型` → 连接到「K采样器」的「模型」端口
  - `CLIP` → 连接到两个「CLIP文本编码」的「clip」端口
  - `VAE` → 连接到「VAE编码」的「vae」端口

### 2. CLIP 文本编码（正面提示词）
- **作用**：将自然语言提示词转换为模型可理解的向量，定义生成图像的正向特征
- **参数设置**：
  ```
  High quality, outstanding, red hair, forest background, green eyes
  高质量，杰出，红色头发，森林背景，绿色眼睛
  ```
- **输出连线**：`条件` → 连接到「K采样器」的「正面条件」端口

### 3. CLIP 文本编码（负面提示词）
- **作用**：定义生成图像需要避免的特征，提升画面质量
- **参数设置**：`easynegative`（通用负面提示词，减少低质量、模糊等问题）
- **输出连线**：`条件` → 连接到「K采样器」的「负面条件」端口

### 4. 加载图像
- **作用**：导入图生图的底图，作为生成的初始图像参考
- **参数设置**：选择本地底图 `test.png`
- **输出连线**：`图像` → 连接到「VAE编码」的「像素」端口

### 5. VAE 编码
- **作用**：将输入的可视化图像转换为模型可处理的潜空间张量（Latent）
- **输入连线**：
  - `像素` → 来自「加载图像」的输出
  - `vae` → 来自「Checkpoint加载器」的VAE输出
- **输出连线**：`Latent` → 连接到「K采样器」的「latent图像」端口

### 6. K采样器
- **作用**：核心生成模块，结合模型、文本条件和初始潜空间张量，生成优化后的潜空间结果
- **参数设置**：
  | 参数名       | 取值       | 说明                     |
  |--------------|------------|--------------------------|
  | 种子         | 77777      | 固定种子保证生成结果可复现 |
  | 生成后控制   | fixed      | 保持生成后参数稳定       |
  | 步数         | 20         | 采样迭代次数，平衡速度与质量 |
  | cfg         | 8.0        | 文本提示词影响强度       |
  | 采样器名称   | dpmpp_2m   | 高效的采样算法，适合二次元生成 |
  | 调度器       | karras     | 提升采样效率与画面细节   |
  | 降噪         | 0.50       | 保留原图50%的基础结构，同时按提示词优化 |
- **输出连线**：`Latent` → 连接到「VAE解码」的「Latent」端口

### 7. 加载 VAE
- **作用**：加载动漫专用优化 VAE（ka-f8-anime2-vae），提升最终图像的细节与色彩表现
- **参数设置**：选择 `ka-f8-anime2-vae-动漫优化.safetensors`
- **输出连线**：`VAE` → 连接到「VAE解码」的「vae」端口

### 8. VAE 解码
- **作用**：将K采样器输出的潜空间张量转换为可视化图像
- **输入连线**：
  - `Latent` → 来自「K采样器」的输出
  - `vae` → 来自「加载VAE」的输出
- **输出连线**：`图像` → 连接到「保存图像」的「图片」端口

### 9. 保存图像
- **作用**：将生成的图像保存到本地
- **参数设置**：文件前缀设为 `ComfyUI`（可自定义）
- **输出**：最终生成的图像会自动保存到 `ComfyUI/output/` 目录

---

## 🔄 工作流完整逻辑
1.  **输入层**：加载底图与生成模型，将文本提示词编码为向量
2.  **编码层**：将底图转换为潜空间张量，为生成做准备
3.  **生成层**：K采样器结合模型、文本条件和初始潜空间，生成优化后的潜空间结果
4.  **解码层**：用专用VAE将潜空间张量转换为高质量可视化图像
5.  **输出层**：保存生成的图像到本地

---

## ✨ 效果与优化建议
- **生成效果**：本案例输出的图像会保留底图的人物构图，同时将头发改为红色、眼睛改为绿色，并添加森林背景，画面细节与色彩通过 `ka-f8-anime2-vae` 优化后更贴合二次元风格。
- **优化建议**：
  1.  若希望更贴近原图，可降低「K采样器」的**降噪值**（如0.3）；若希望完全重构画面，可提高降噪值（如0.8）。
  2.  增加**步数**（如30）可提升画面细节，但会增加生成时间。
  3.  更换**采样器**（如 `dpmpp_2m_sde`）可获得不同的画面质感。

---
